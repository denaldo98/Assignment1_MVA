---
title: "MCA applied to Bicing data"
output:
  html_notebook: default
  html_document:
    df_print: paged
  pdf_document: default
---

```{r}
# install needed packages
#install.packages(c("FactoMineR", "factoextra", "dplyr"))
```

```{r}
# load libraries
library(FactoMineR)
library(factoextra)
library(dplyr)
```

## Exploratory data analysis

```{r}
bicing <- read.csv(file='bicing.csv', header=TRUE, sep=";", dec=",")
```

Before applying MCA, let's first explore the dataset.

```{r}
# inspect the dataset
bicing
```

By reading the columns, we can understand that this dataset has been made from data gathered by the Bicing company, offering bike rental service in Barcelona.

Each row of the dataset represents a rental with information such as:

-   Rental start and end date (Start.date, Start.time, End.date, End.time, Total.duration, ...)

-   Information on the start and end stations (identification with Start.station.number or End.station.number, position and altitude with Altitude.E or End.lat for example)

-   Weather information, although we don't know if the data is related to the start or end station (or not any of those). We will assume that it is the weather in the city over the day.

    We have in total 4.877 individuals

Let's see a brief summary of the main statistics of the dataset:

```{r}
summary(bicing)
```

About our variables' type, we have categorical variables: \* Start.weekday, Weekend, Nightout, Period \* Metro.staion.S, Metro.station.E, Metro.sORe and Metro.sANDe \* Loop \* Account.type \* Weather.main \* Downtown.S and Downtown.E

## MCA

We'll perform multiple correspondence analysis (MCA) by considering a ventilation level of 1% for the
infrequent categories and saving the results of the first 10 dimensions. We'll use as active variables:
"Start.weekday", "Period", "Metro.station.E", "Downtown.E", "Account.type" and
"Weather.main". Define "Month" and "Temperature" as supplementary variables.

Since we are not using all the variables as active, we will create a new dataframe with only the relevant columns for our analysis:

```{r}
#X = bicing[c("Start.weekday", "Weekend", "Nightout", "Period",   "Metro.station.S", "Metro.station.E", "Metro.sORe", "Metro.sANDe"        , "Downtown.S", "Downtown.E", "Loop", "Account.type", "Weather.main")]

#bicing_mca = MCA(X, ncp=10, quali.sup=c(1, 4, 6, 10, 12, 13))

X2 = bicing[c("Start.weekday", "Period", "Metro.station.E", "Downtown.E",  "Account.type", "Weather.main", "Month", "Temperature")] 
```

```{r}
X2
```

The new dataframe has 4877 individuals ( I ) and 8 columns: the first 6 will be our active categorical variables for the MCA ( J ), while "Month" will be threated as a supplementary categorical variable, and "Temperature" as a supplementary quantitative variable.

Let's now set the correct types for the column variables

```{r}
summary(X2["Month"])
```

As we can see from above, the variable "Month" is threated as a quantitative variable, while it assumes only 8 discrete values as shown below:

```{r}
unique(X2[, "Month"])
```

To solve this issue we transform it into a categorical variable:

```{r}
X2[,"Month"] = as.factor(X2[,"Month"])
```

We now transform all the active variables into categorical ones:

```{r}
X2[,"Period"] = as.factor(X2[,"Period"])
X2[,"Start.weekday"] = as.factor(X2[,"Start.weekday"])
X2[,"Metro.station.E"] = as.factor(X2[,"Metro.station.E"])
X2[,"Downtown.E"] = as.factor(X2[,"Downtown.E"])
X2[,"Account.type"] = as.factor(X2[,"Account.type"])
X2[,"Weather.main"] = as.factor(X2[,"Weather.main"])
```

```{r}
print(unique(X2[, "Period"]))
print(unique(X2[, "Start.weekday"]))
print(unique(X2[, "Metro.station.E"]))
print(unique(X2[, "Downtown.E"]))
print(unique(X2[, "Account.type"]))
print(unique(X2[, "Weather.main"]))
```

Let's see now the summary of our dataframe

```{r}
summary(X2)
```

It's also possible to plot the frequency of variable categories

```{r}
for (i in 1:6) {
  plot(X2[,i], main=colnames(X2)[i],
       ylab = "Count", col="steelblue", las = 2)
  }
```

We are now ready to perform MCA

```{r}
?MCA
```

We use the MCA function of the FactoMineR package and we specify the number of dimensions to keep in the final results by means of the parameter ncp.

```{r}
bicing_mca = MCA(X2, ncp=10, quali.sup = 7,  quanti.sup=8, level.ventil=0.01, graph = FALSE)
```

## Questions

***What is the number of dimensions that this MCA generates? What does this value equal?***

```{r}
bicing_mca$eig
```

MCA generates 16 dimensions which all together explain 100% of the variance of the original data.

We know that the number of dimensions generated by MCA is given by K - J, where K represents the total number of categories of the active categorical variables, while J represents the number of active categorical variables.

In our case J is equal to 6, while K is equal to the sum of the categories of each active categorical variable: 7 + 5 + 2 + 2 + 2 + 8 which is equal to 26.

Therefore we should obtain 20 dimensions/eigenvalues . This would be the case where no ventilation level is applied but, since we apply a ventilation of 0.01 we obtain 4 dimensions less . Indeed a 1% ventilation level removes rare categories.

Among these 10 dimensions we tell the algorithm to keep only the first 10 in the final result, becasue of the argument ncp.

```{r}
bicing_mca
```

### Visualization and Interpretation

Let's now analyze the ouputs of the CA

#### Eigenvalues

```{r}
bicing_mca$eig
```

##### Scree Plot

Let's graphically visualize the obtained eigenvalues by looking at the Scree Plot

```{r}
fviz_screeplot(bicing_mca, addlabels = TRUE, ylim = c(0, 65))
```

From the graph above and from the values seen before, we can easily conclude that the first 2 dimensions are enough to describe the entire cloud of points, since they capture more than 90% of the total inertia of the cloud of points, i.e. they capture the largest percentage of the deviation from independence of our dataset. Therefore, an analysis on the plane consisting of the first 2 dimensions would be sufficient to extract conclusions from the performed CA. <br> <br>

#### Plots

Let's now try to build some meaningful plots, since the full CA plot contains overlapping points

```{r}
??plot.CA 
```

```{r}
#plot.CA(res.ca, cex=0.7, shadowtext = "True", label=c("col"))
```

The function fviz_ca_biplot() of the package "factoextra" can be used to draw the biplot of rows and columns variables, i.e. to provide a simultaneous representation of rows and columns

```{r}
?fviz_mca_biplot # provides ggplot-based elegant visualizations of CA outputs
```

```{r}
options(ggrepel.max.overlaps = 6) # max number of allowed overlaps (for all the current session) 
fviz_ca_biplot(res.ca, repel=TRUE) # repel= TRUE to avoid text overlapping
```

Rows are represented as blue points and cols as red triangles. The distance between any row points or column points gives a measure of their similarity (or dissimilarity). Row points with similar profile are closed on the factor map. The same holds true for column points.

The graph shows that some causes of death are mostly present in younger people, i.e. we can see a high proximity between younger people and "Road accidents", "Complications in pregnanccy and birth",.. We can see that older people share a lot of causes of death.

Only age ranges 15-24, 25-34, 35-44, 45-54 are far from the origin

##### Interpretation of the 1st factorial plane

Most of the deviation from independence comes from the separation of the young age ranges, i.e. 15-24, 25-34, 35-44 and the rest. This is well captured by the 1st dimension which separates young people (on the right side) from old people (on the left of the origin).The 2nd dimension separates the age-range 15.24(in the top) from the rest of the ranges: in particular it shows an opposition of the that range with the range 45-54 and 55-64. The position of each cause of death shows the range of age it affects more. For instance, we can see that causes of death in the first quadrant of the biplot are mostly related to young age-ranges.

Since the previous biplot is pretty difficult to interpret, we show only the rows contributing more to the first 2 dim

```{r}
#plot.CA(res.ca,selectRow ="contrib ",selectCol = "contrib 5") 
#fviz_ca_biplot(res.ca, repel=TRUE, select.row = list(contrib = 8))
plot.CA(res.ca, selectRow ="contrib 10", shadow=TRUE, cex=0.7, unselect = 0.92, autoLab="auto")
```

#### Row analysis

```{r}
#head(res.ca$row)
# Output to long to visualize
```

##### Coordinates of row points

```{r}
head(bicing_mca$row$coord)  # coordinates of the row points (i.e. causes od death) in the new dimensions
```

```{r}
# visualize only row points
fviz_ca_row(res.ca, repel = TRUE, col.row="steelblue", shape.row = 15) # change shape and color of the row points
```

The plot above shows the relationships between row points:

Rows with a similar profile are grouped together. Negatively correlated rows are positioned on opposite sides of the plot origin (opposed quadrants). The distance between row points and the origin measures the quality of the row points on the factor map. Row points that are away from the origin are well represented on the factor map.

##### Quality of representation of rows

The result of the analysis shows that, the contingency table has been successfully represented in low dimension space using correspondence analysis. The two dimensions 1 and 2 are sufficient to retain more than 90% of the total inertia (variation) contained in the data.

However, not all the points are equally well displayed in the two dimensions.

The quality of representation of the rows on the new dimensions is called the squared cosine (cos2) or the squared correlations.

The cos2 measures the degree of association between rows/columns and a particular axis. The cos2 of row points can be extracted as follow:

```{r}
head(bicing_mca$row$cos2,3) # quality of representation of first 3 row points
```

The values of the cos2 are comprised between 0 and 1. The sum of the cos2 for rows on all the CA dimensions is equal to one.

The quality of representation of a row or column in n dimensions is simply the sum of the squared cosine of that row or column over the n dimensions.

If a row item is well represented by two dimensions, the sum of the cos2 is closed to one. For some of the row items, more than 2 dimensions are required to perfectly represent the data.

It's possible to color row points by their cos2 values using the argument col.row = "cos2". This produces a gradient colors, which can be customized using the argument gradient.cols. For instance, gradient.cols = c("white", "blue", "red") means that:

-   variables with low cos2 values will be colored in "white"
-   variables with mid cos2 values will be colored in "blue"
-   variables with high cos2 values will be colored in "red"

```{r}
# Color by cos2 values: quality on the factor map
fviz_ca_row(res.ca, col.row = "cos2",
             gradient.cols = c("white", "blue", "red"), 
             repel = TRUE)
```

Note that, it's also possible to change the transparency of the row points according to their cos2 values using the option alpha.row = "cos2":

```{r}
# Change the transparency by cos2 values
fviz_ca_row(res.ca, repel=TRUE, alpha.row="cos2")
```

It's also possible to create a bar plot of rows cos2 using the function fviz_cos2() (in factoextra):

```{r}
?fviz_cos2
```

```{r}
# Cos2 of rows on Dim.1 and Dim.2
fviz_cos2(res.ca, choice = "row", axes = 1:2, repel=TRUE, top=15) # show only top 15
```

##### Contributions of rows to the dimensions

```{r}
head(res.ca$row$contrib)
```

The row variables with the larger value, contribute the most to the definition of the dimensions.

The function fviz_contrib() of factoextra package can be used to draw a bar plot of row contributions. If your data contains many rows, you can decide to show only the top contributing rows. The R code below shows the top 10 rows contributing to the dimensions:

```{r}
# Bar plot of the contributions of rows to dimension 1
fviz_contrib(res.ca, choice = "row", axes = 1, top = 15)
```

The total contribution to dimension 1 and 2 can be obtained as follow:

```{r}
fviz_contrib(res.ca, choice = "row", axes = 1:2, top = 15)
```

The rows "Road accidents", "Suicides", "Other accidents" are the most important in the definition of the first dimension

```{r}
# Contributions of rows to dimension 2
fviz_contrib(res.ca, choice = "row", axes = 2, top = 15)
```

The most important (or, contributing) row points can be highlighted on the plot of row points as follows:

```{r}
fviz_ca_row(res.ca, col.row = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE)
```

Note that, it's also possible to control the transparency of row points according to their contribution values using the option alpha.row = "contrib", as shown below:

```{r}
# Change the transparency by contrib values
fviz_ca_row(res.ca, alpha.row="contrib",
             repel = TRUE)
```

#### Column analysis

```{r}
#head(res.ca$col)
# Output to long to visualize
```

##### Coordinates of column points

```{r}
head(res.ca$col$coord)  # coordinates of the column points (i.e. age ranges) in the new dimensions
```

```{r}
# visualize only col points
fviz_ca_col(res.ca, repel = TRUE) 
```

The plot above shows the relationships between column points:

Rows with a similar profile are grouped together. Negatively correlated rows are positioned on opposite sides of the plot origin (opposed quadrants). The distance between row points and the origin measures the quality of the row points on the factor map. Row points that are away from the origin are well represented on the factor map.

##### Quality of representation of columns

The result of the analysis shows that, the contingency table has been successfully represented in low dimension space using correspondence analysis. The two dimensions 1 and 2 are sufficient to retain 90% of the total inertia (variation) contained in the data.

However, not all the points are equally well displayed in the two dimensions.

The quality of representation of the rows on the factor map is called the squared cosine (cos2) or the squared correlations.

The cos2 measures the degree of association between rows/columns and a particular axis. The cos2 of row points can be extracted as follow:

```{r}
res.ca$col$cos2 # quality of representation of first 3 col points
```

The values of the cos2 are comprised between 0 and 1. The sum of the cos2 for rows on all the CA dimensions is equal to one.

The quality of representation of a row or column in n dimensions is simply the sum of the squared cosine of that row or column over the n dimensions.

If a row item is well represented by two dimensions, the sum of the cos2 is closed to one. For some of the row items, more than 2 dimensions are required to perfectly represent the data.

It's possible to color row points by their cos2 values using the argument col.row = "cos2". This produces a gradient colors, which can be customized using the argument gradient.cols. For instance, gradient.cols = c("white", "blue", "red") means that:

variables with low cos2 values will be colored in "white" variables with mid cos2 values will be colored in "blue" variables with high cos2 values will be colored in red

```{r}
# Color by cos2 values: quality on the factor map
fviz_ca_col(res.ca, col.col = "cos2",
             gradient.cols = c("white", "blue", "red"), 
             repel = TRUE)
```

Note that, it's also possible to change the transparency of the row points according to their cos2 values using the option alpha.row = "cos2". For example, type this:

```{r}
# Change the transparency by cos2 values
fviz_ca_col(res.ca, repel=TRUE, alpha.col ="cos2")
```

It's also possible to create a bar plot of cols cos2 using the function fviz_cos2() (in factoextra):

```{r}
# Cos2 of rows on Dim.1 and Dim.2
fviz_cos2(res.ca, choice = "col", axes = 1:2, repel=TRUE, top=15) # show only top 15
```

Recall that, the value of the cos2 is between 0 and 1. A cos2 closed to 1 corresponds to a column/row variables that are well represented on the factor map.

##### Contributions of cols to the dimensions

```{r}
head(res.ca$col$contrib)
```

The row variables with the larger value, contribute the most to the definition of the dimensions.

The function fviz_contrib() [factoextra package] can be used to draw a bar plot of row contributions. If your data contains many rows, you can decide to show only the top contributing rows. The R code below shows the top 10 rows contributing to the dimensions:

```{r}
# Contributions of cols to dimension 1
fviz_contrib(res.ca, choice = "col", axes = 1)
```

The total contribution to dimension 1 and 2 can be obtained as follow:

```{r}
fviz_contrib(res.ca, choice = "col", axes = 1:2)
```

The rows "Road accidents", "Suicides", "Other accidents" are the most important in the definition of the first dimension

```{r}
# Contributions of cols to dimension 2
fviz_contrib(res.ca, choice = "col", axes = 2, top = 10)
```

The most important (or, contributing) row points can be highlighted on the biplot as follows:

```{r}
fviz_ca_col(res.ca, col.col =  "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), 
             repel = TRUE)
```

Note that, it's also possible to control the transparency of row points according to their contribution values using the option alpha.row = "contrib", as shown below:

```{r}
# Change the transparency by contrib values
fviz_ca_col(res.ca, alpha.col="contrib",
             repel = TRUE)
```
